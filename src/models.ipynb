{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.svm import SVC\n",
    "import time\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.decomposition import PCA\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import sklearn\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6383, 41) Index(['FTR', 'FTHG-H', 'FTAG-H', 'FTR-H', 'HTHG-H', 'HTAG-H', 'HTR-H', 'HS-H',\n",
      "       'AS-H', 'HST-H', 'AST-H', 'HC-H', 'AC-H', 'HF-H', 'AF-H', 'HY-H',\n",
      "       'AY-H', 'HR-H', 'AR-H', 'FTHG-A', 'FTAG-A', 'FTR-A', 'HTHG-A', 'HTAG-A',\n",
      "       'HTR-A', 'HS-A', 'AS-A', 'HST-A', 'AST-A', 'HC-A', 'AC-A', 'HF-A',\n",
      "       'AF-A', 'HY-A', 'AY-A', 'HR-A', 'AR-A', 'HomeForm', 'AwayForm',\n",
      "       'PreviousEncounters', 'HomePreviousPosition', 'AwayPreviousPosition'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "datapath='/Users/soni6/github/soccer-analytics/data/archive/Datasets'\n",
    "finalData=pd.read_csv(datapath+'/finalData.csv')\n",
    "\n",
    "# finalData=finalData[finalData['FTR']!=0]\n",
    "X=finalData.drop(columns=['FTR'])\n",
    "# X=X.drop(columns=['HomeForm','AwayForm'])\n",
    "y=finalData['FTR']\n",
    "print(X.shape,finalData.columns)\n",
    "\n",
    "#Define scaler (we're using the defaults here)\n",
    "MMS = MinMaxScaler()\n",
    "#Apply transformation \n",
    "X = MMS.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, shuffle=False)\n",
    "pca = PCA()\n",
    "X_train_pca = pca.fit_transform(X_train)\n",
    "X_test_pca = pca.fit_transform(X_test)\n",
    "plt.bar(range(1, 42), pca.explained_variance_ratio_, alpha=0.5, align='center')\n",
    "# plt.step(range(1, 110), np.cumsum(pca.explained_variance_ratio_), where='mid')\n",
    "plt.ylabel('Explained variance ratio')\n",
    "plt.xlabel('Principal components')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best model is: {'estimator__n_neighbors': 200, 'estimator__p': 1, 'estimator__weights': 'distance'}\n",
      "\n",
      "The accuracy of the best model is: 0.5136520914746922\n",
      "Time to train 53.89\n",
      "Testing set accuracy 0.5488250652741514\n"
     ]
    }
   ],
   "source": [
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, shuffle=False)\n",
    "\n",
    "#Define and fit model\n",
    "#Choose some parameters to search over\n",
    "params = {\n",
    "    'estimator__n_neighbors': [20,50,200,500],\n",
    "    \"estimator__weights\": ['distance'],\n",
    "    \"estimator__p\":[1,2]\n",
    "}\n",
    "model_to_set = OneVsRestClassifier(KNeighborsRegressor())\n",
    "model = GridSearchCV(model_to_set, params, cv=3, scoring='accuracy', return_train_score=True)\n",
    "t1=time.time()\n",
    "model.fit(X_train,y_train)\n",
    "\n",
    "#Print out some results\n",
    "print(\"The best model is:\",model.best_params_)\n",
    "print(\"\\nThe accuracy of the best model is:\", model.best_score_)\n",
    "t2=time.time()\n",
    "print(\"Time to train\", round(t2-t1,2))\n",
    "\n",
    "y_preds = model.predict(X_test)\n",
    "accuracy = sklearn.metrics.accuracy_score(y_test, y_preds)\n",
    "# fpr, tpr, thresholds = roc_curve(y_test, y_preds, pos_label=1)\n",
    "# auc_roc = auc(fpr, tpr)\n",
    "print(\"Testing set accuracy\",accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# pca = PCA(n_components = 30)\n",
    "# X_train_pca = pca.fit_transform(X_train)\n",
    "# X_test_pca = pca.fit_transform(X_test)\n",
    "# # comment below if without PCA\n",
    "# X_train=X_train_pca\n",
    "# X_test=X_test_pca\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best model is: {'estimator__C': 10, 'estimator__kernel': 'linear'}\n",
      "\n",
      "The accuracy of the best model is: 0.5584173574144772\n",
      "Time to train 66.02\n",
      "Testing set accuracy 0.5827676240208878\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'mean_fit_time': array([0.63016105, 1.04964566, 1.09574413, 0.61712869, 1.95791173,\n",
       "        1.03168575, 0.99849391, 9.94800019, 1.43591865]),\n",
       " 'std_fit_time': array([0.01095731, 0.03981758, 0.10359627, 0.01127321, 0.02593453,\n",
       "        0.02594046, 0.0284702 , 0.30826929, 0.03180793]),\n",
       " 'mean_score_time': array([0.22949894, 0.24487638, 0.37187592, 0.20828859, 0.24626152,\n",
       "        0.35153937, 0.226379  , 0.23217106, 0.36224   ]),\n",
       " 'std_score_time': array([0.00934442, 0.00690938, 0.01400829, 0.00419309, 0.00743162,\n",
       "        0.00099986, 0.00457163, 0.00722127, 0.00696231]),\n",
       " 'param_estimator__C': masked_array(data=[0.1, 0.1, 0.1, 1, 1, 1, 10, 10, 10],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_estimator__kernel': masked_array(data=['linear', 'poly', 'rbf', 'linear', 'poly', 'rbf',\n",
       "                    'linear', 'poly', 'rbf'],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'params': [{'estimator__C': 0.1, 'estimator__kernel': 'linear'},\n",
       "  {'estimator__C': 0.1, 'estimator__kernel': 'poly'},\n",
       "  {'estimator__C': 0.1, 'estimator__kernel': 'rbf'},\n",
       "  {'estimator__C': 1, 'estimator__kernel': 'linear'},\n",
       "  {'estimator__C': 1, 'estimator__kernel': 'poly'},\n",
       "  {'estimator__C': 1, 'estimator__kernel': 'rbf'},\n",
       "  {'estimator__C': 10, 'estimator__kernel': 'linear'},\n",
       "  {'estimator__C': 10, 'estimator__kernel': 'poly'},\n",
       "  {'estimator__C': 10, 'estimator__kernel': 'rbf'}],\n",
       " 'split0_test_score': array([0.53087248, 0.55234899, 0.52147651, 0.54765101, 0.50268456,\n",
       "        0.54697987, 0.54966443, 0.42751678, 0.47114094]),\n",
       " 'split1_test_score': array([0.53055742, 0.54533244, 0.52316991, 0.5560779 , 0.53660175,\n",
       "        0.53458697, 0.56279382, 0.4754869 , 0.5003358 ]),\n",
       " 'split2_test_score': array([0.52652787, 0.55339154, 0.51914036, 0.56010745, 0.50369375,\n",
       "        0.54130289, 0.56279382, 0.44123573, 0.48623237]),\n",
       " 'mean_test_score': array([0.52931926, 0.55035766, 0.52126226, 0.55461212, 0.51432669,\n",
       "        0.54095657, 0.55841736, 0.4480798 , 0.48590304]),\n",
       " 'std_test_score': array([0.001978  , 0.00357877, 0.00165202, 0.00518987, 0.01575623,\n",
       "        0.0050653 , 0.00618925, 0.02017282, 0.01192102]),\n",
       " 'rank_test_score': array([5, 3, 6, 2, 7, 4, 1, 9, 8], dtype=int32)}"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# with grid search \n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, shuffle=False)\n",
    "model_to_set = OneVsRestClassifier(SVC(gamma='scale'))\n",
    "parameters = {\n",
    "    \"estimator__C\": [0.1,1,10],\n",
    "    \"estimator__kernel\": [\"linear\",\"poly\",\"rbf\"],\n",
    "}\n",
    "t1=time.time()\n",
    "clfSV = GridSearchCV(model_to_set,cv=3,scoring='accuracy', param_grid=parameters)\n",
    "\n",
    "clfSV.fit(X_train,y_train)\n",
    "\n",
    "#Print out some results\n",
    "print(\"The best model is:\",clfSV.best_params_)\n",
    "print(\"\\nThe accuracy of the best model is:\", clfSV.best_score_)\n",
    "t2=time.time()\n",
    "print(\"Time to train\", round(t2-t1,2))\n",
    "\n",
    "\n",
    "y_preds = clfSV.predict(X_test)\n",
    "# fpr, tpr, thresholds = roc_curve(y_test, y_preds, pos_label=1)\n",
    "# auc_roc = auc(fpr, tpr)\n",
    "accuracy = sklearn.metrics.accuracy_score(y_test, y_preds)\n",
    "print(\"Testing set accuracy\",accuracy)\n",
    "\n",
    "clfSV.cv_results_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from keras.utils import np_utils\n",
    "\n",
    "o=np.ones(X.shape[0])\n",
    "o=o.reshape(X.shape[0],1)\n",
    "# X=np.hstack((X,o))\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, shuffle=False)\n",
    "\n",
    "encoder = LabelEncoder()\n",
    "\n",
    "# training\n",
    "encoder.fit(y_train)\n",
    "encoded_y_train = encoder.transform(y_train)\n",
    "# convert integers to dummy variables (i.e. one hot encoded)\n",
    "dummy_y_train = np_utils.to_categorical(encoded_y_train)\n",
    "# testing\n",
    "encoder.fit(y_test)\n",
    "encoded_y_test = encoder.transform(y_test)\n",
    "# convert integers to dummy variables (i.e. one hot encoded)\n",
    "dummy_y_test = np_utils.to_categorical(encoded_y_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "4468/4468 [==============================] - 1s 244us/step - loss: 0.9689 - accuracy: 0.4738\n",
      "Epoch 2/100\n",
      "4468/4468 [==============================] - 0s 65us/step - loss: 0.9192 - accuracy: 0.5065\n",
      "Epoch 3/100\n",
      "4468/4468 [==============================] - 0s 62us/step - loss: 0.9109 - accuracy: 0.4969\n",
      "Epoch 4/100\n",
      "4468/4468 [==============================] - 0s 66us/step - loss: 0.8966 - accuracy: 0.5143\n",
      "Epoch 5/100\n",
      "4468/4468 [==============================] - 0s 63us/step - loss: 0.8864 - accuracy: 0.5137\n",
      "Epoch 6/100\n",
      "4468/4468 [==============================] - 0s 66us/step - loss: 0.8749 - accuracy: 0.5029\n",
      "Epoch 7/100\n",
      "4468/4468 [==============================] - 0s 69us/step - loss: 0.8674 - accuracy: 0.5121\n",
      "Epoch 8/100\n",
      "4468/4468 [==============================] - 0s 65us/step - loss: 0.8612 - accuracy: 0.5090\n",
      "Epoch 9/100\n",
      "4468/4468 [==============================] - 0s 70us/step - loss: 0.8594 - accuracy: 0.5083\n",
      "Epoch 10/100\n",
      "4468/4468 [==============================] - 0s 72us/step - loss: 0.8534 - accuracy: 0.5107\n",
      "Epoch 11/100\n",
      "4468/4468 [==============================] - 0s 66us/step - loss: 0.8544 - accuracy: 0.5114\n",
      "Epoch 12/100\n",
      "4468/4468 [==============================] - 0s 62us/step - loss: 0.8480 - accuracy: 0.5157\n",
      "Epoch 13/100\n",
      "4468/4468 [==============================] - 0s 65us/step - loss: 0.8493 - accuracy: 0.5047\n",
      "Epoch 14/100\n",
      "4468/4468 [==============================] - 0s 65us/step - loss: 0.8642 - accuracy: 0.5022\n",
      "Epoch 15/100\n",
      "4468/4468 [==============================] - 0s 63us/step - loss: 0.8407 - accuracy: 0.5132\n",
      "Epoch 16/100\n",
      "4468/4468 [==============================] - 0s 64us/step - loss: 0.8435 - accuracy: 0.5060\n",
      "Epoch 17/100\n",
      "4468/4468 [==============================] - 0s 66us/step - loss: 0.8472 - accuracy: 0.5047\n",
      "Epoch 18/100\n",
      "4468/4468 [==============================] - 0s 62us/step - loss: 0.8376 - accuracy: 0.5192\n",
      "Epoch 19/100\n",
      "4468/4468 [==============================] - 0s 63us/step - loss: 0.8378 - accuracy: 0.5166\n",
      "Epoch 20/100\n",
      "4468/4468 [==============================] - 0s 62us/step - loss: 0.8322 - accuracy: 0.5145\n",
      "Epoch 21/100\n",
      "4468/4468 [==============================] - 0s 66us/step - loss: 0.8354 - accuracy: 0.5121\n",
      "Epoch 22/100\n",
      "4468/4468 [==============================] - 0s 63us/step - loss: 0.8279 - accuracy: 0.5188\n",
      "Epoch 23/100\n",
      "4468/4468 [==============================] - 0s 65us/step - loss: 0.8354 - accuracy: 0.5239\n",
      "Epoch 24/100\n",
      "4468/4468 [==============================] - 0s 68us/step - loss: 0.8237 - accuracy: 0.5166\n",
      "Epoch 25/100\n",
      "4468/4468 [==============================] - 0s 65us/step - loss: 0.8290 - accuracy: 0.5114\n",
      "Epoch 26/100\n",
      "4468/4468 [==============================] - 0s 65us/step - loss: 0.8257 - accuracy: 0.5179\n",
      "Epoch 27/100\n",
      "4468/4468 [==============================] - 0s 67us/step - loss: 0.8231 - accuracy: 0.5257\n",
      "Epoch 28/100\n",
      "4468/4468 [==============================] - 0s 69us/step - loss: 0.8170 - accuracy: 0.5213\n",
      "Epoch 29/100\n",
      "4468/4468 [==============================] - 0s 67us/step - loss: 0.8273 - accuracy: 0.5293\n",
      "Epoch 30/100\n",
      "4468/4468 [==============================] - 0s 65us/step - loss: 0.8115 - accuracy: 0.5266\n",
      "Epoch 31/100\n",
      "4468/4468 [==============================] - 0s 69us/step - loss: 0.8116 - accuracy: 0.5251\n",
      "Epoch 32/100\n",
      "4468/4468 [==============================] - 0s 74us/step - loss: 0.8121 - accuracy: 0.5199\n",
      "Epoch 33/100\n",
      "4468/4468 [==============================] - 0s 65us/step - loss: 0.8113 - accuracy: 0.5291\n",
      "Epoch 34/100\n",
      "4468/4468 [==============================] - 0s 72us/step - loss: 0.8246 - accuracy: 0.5107\n",
      "Epoch 35/100\n",
      "4468/4468 [==============================] - 0s 62us/step - loss: 0.8240 - accuracy: 0.5018\n",
      "Epoch 36/100\n",
      "4468/4468 [==============================] - 0s 62us/step - loss: 0.8079 - accuracy: 0.5253\n",
      "Epoch 37/100\n",
      "4468/4468 [==============================] - 0s 68us/step - loss: 0.8045 - accuracy: 0.5257\n",
      "Epoch 38/100\n",
      "4468/4468 [==============================] - 0s 70us/step - loss: 0.8029 - accuracy: 0.5275\n",
      "Epoch 39/100\n",
      "4468/4468 [==============================] - 0s 66us/step - loss: 0.8145 - accuracy: 0.5278\n",
      "Epoch 40/100\n",
      "4468/4468 [==============================] - 0s 64us/step - loss: 0.8061 - accuracy: 0.5175\n",
      "Epoch 41/100\n",
      "4468/4468 [==============================] - 0s 84us/step - loss: 0.8114 - accuracy: 0.5237\n",
      "Epoch 42/100\n",
      "4468/4468 [==============================] - 0s 70us/step - loss: 0.8041 - accuracy: 0.5327\n",
      "Epoch 43/100\n",
      "4468/4468 [==============================] - 0s 65us/step - loss: 0.8005 - accuracy: 0.5280\n",
      "Epoch 44/100\n",
      "4468/4468 [==============================] - 0s 69us/step - loss: 0.8007 - accuracy: 0.5239\n",
      "Epoch 45/100\n",
      "4468/4468 [==============================] - 0s 64us/step - loss: 0.8114 - accuracy: 0.5231\n",
      "Epoch 46/100\n",
      "4468/4468 [==============================] - 0s 68us/step - loss: 0.8064 - accuracy: 0.5378\n",
      "Epoch 47/100\n",
      "4468/4468 [==============================] - 0s 72us/step - loss: 0.7999 - accuracy: 0.5311\n",
      "Epoch 48/100\n",
      "4468/4468 [==============================] - 0s 63us/step - loss: 0.8040 - accuracy: 0.5291\n",
      "Epoch 49/100\n",
      "4468/4468 [==============================] - 0s 65us/step - loss: 0.7976 - accuracy: 0.5333\n",
      "Epoch 50/100\n",
      "4468/4468 [==============================] - 0s 67us/step - loss: 0.7990 - accuracy: 0.5204\n",
      "Epoch 51/100\n",
      "4468/4468 [==============================] - 0s 69us/step - loss: 0.8097 - accuracy: 0.5300\n",
      "Epoch 52/100\n",
      "4468/4468 [==============================] - 0s 67us/step - loss: 0.8010 - accuracy: 0.5284\n",
      "Epoch 53/100\n",
      "4468/4468 [==============================] - 0s 63us/step - loss: 0.8008 - accuracy: 0.5405\n",
      "Epoch 54/100\n",
      "4468/4468 [==============================] - 0s 68us/step - loss: 0.7908 - accuracy: 0.5380\n",
      "Epoch 55/100\n",
      "4468/4468 [==============================] - 0s 78us/step - loss: 0.7946 - accuracy: 0.5347\n",
      "Epoch 56/100\n",
      "4468/4468 [==============================] - 0s 69us/step - loss: 0.7951 - accuracy: 0.5436\n",
      "Epoch 57/100\n",
      "4468/4468 [==============================] - 0s 67us/step - loss: 0.7975 - accuracy: 0.5235\n",
      "Epoch 58/100\n",
      "4468/4468 [==============================] - 0s 69us/step - loss: 0.8094 - accuracy: 0.5186\n",
      "Epoch 59/100\n",
      "4468/4468 [==============================] - 0s 68us/step - loss: 0.7892 - accuracy: 0.5278\n",
      "Epoch 60/100\n",
      "4468/4468 [==============================] - 0s 68us/step - loss: 0.7892 - accuracy: 0.5340\n",
      "Epoch 61/100\n",
      "4468/4468 [==============================] - 0s 71us/step - loss: 0.7954 - accuracy: 0.5311\n",
      "Epoch 62/100\n",
      "4468/4468 [==============================] - 0s 75us/step - loss: 0.7928 - accuracy: 0.5345\n",
      "Epoch 63/100\n",
      "4468/4468 [==============================] - 0s 70us/step - loss: 0.7858 - accuracy: 0.5327\n",
      "Epoch 64/100\n",
      "4468/4468 [==============================] - 0s 69us/step - loss: 0.7845 - accuracy: 0.5333\n",
      "Epoch 65/100\n",
      "4468/4468 [==============================] - 0s 66us/step - loss: 0.7904 - accuracy: 0.5278\n",
      "Epoch 66/100\n",
      "4468/4468 [==============================] - 0s 66us/step - loss: 0.7962 - accuracy: 0.5304\n",
      "Epoch 67/100\n",
      "4468/4468 [==============================] - 0s 67us/step - loss: 0.7781 - accuracy: 0.5403\n",
      "Epoch 68/100\n",
      "4468/4468 [==============================] - 0s 67us/step - loss: 0.7834 - accuracy: 0.5385\n",
      "Epoch 69/100\n",
      "4468/4468 [==============================] - 0s 68us/step - loss: 0.7793 - accuracy: 0.5398\n",
      "Epoch 70/100\n",
      "4468/4468 [==============================] - 0s 73us/step - loss: 0.7876 - accuracy: 0.5378\n",
      "Epoch 71/100\n",
      "4468/4468 [==============================] - 0s 71us/step - loss: 0.7771 - accuracy: 0.5445\n",
      "Epoch 72/100\n",
      "4468/4468 [==============================] - 0s 68us/step - loss: 0.7828 - accuracy: 0.5365\n",
      "Epoch 73/100\n",
      "4468/4468 [==============================] - 0s 72us/step - loss: 0.7898 - accuracy: 0.5340\n",
      "Epoch 74/100\n",
      "4468/4468 [==============================] - 0s 64us/step - loss: 0.7834 - accuracy: 0.5394\n",
      "Epoch 75/100\n",
      "4468/4468 [==============================] - 0s 65us/step - loss: 0.7889 - accuracy: 0.5443\n",
      "Epoch 76/100\n",
      "4468/4468 [==============================] - 0s 66us/step - loss: 0.7855 - accuracy: 0.5322\n",
      "Epoch 77/100\n",
      "4468/4468 [==============================] - 0s 71us/step - loss: 0.7829 - accuracy: 0.5345\n",
      "Epoch 78/100\n",
      "4468/4468 [==============================] - 0s 65us/step - loss: 0.7769 - accuracy: 0.5423\n",
      "Epoch 79/100\n",
      "4468/4468 [==============================] - 0s 65us/step - loss: 0.7742 - accuracy: 0.5349\n",
      "Epoch 80/100\n",
      "4468/4468 [==============================] - 0s 67us/step - loss: 0.7733 - accuracy: 0.5403\n",
      "Epoch 81/100\n",
      "4468/4468 [==============================] - 0s 65us/step - loss: 0.7945 - accuracy: 0.5421\n",
      "Epoch 82/100\n",
      "4468/4468 [==============================] - 0s 65us/step - loss: 0.7756 - accuracy: 0.5363\n",
      "Epoch 83/100\n",
      "4468/4468 [==============================] - 0s 66us/step - loss: 0.7748 - accuracy: 0.5501\n",
      "Epoch 84/100\n",
      "4468/4468 [==============================] - 0s 66us/step - loss: 0.7941 - accuracy: 0.5329\n",
      "Epoch 85/100\n",
      "4468/4468 [==============================] - 0s 65us/step - loss: 0.7803 - accuracy: 0.5445\n",
      "Epoch 86/100\n",
      "4468/4468 [==============================] - 0s 64us/step - loss: 0.7704 - accuracy: 0.5403\n",
      "Epoch 87/100\n",
      "4468/4468 [==============================] - 0s 67us/step - loss: 0.7737 - accuracy: 0.5463\n",
      "Epoch 88/100\n",
      "4468/4468 [==============================] - 0s 68us/step - loss: 0.7902 - accuracy: 0.5575\n",
      "Epoch 89/100\n",
      "4468/4468 [==============================] - 0s 65us/step - loss: 0.7761 - accuracy: 0.5416\n",
      "Epoch 90/100\n",
      "4468/4468 [==============================] - 0s 67us/step - loss: 0.7706 - accuracy: 0.5472\n",
      "Epoch 91/100\n",
      "4468/4468 [==============================] - 0s 68us/step - loss: 0.7822 - accuracy: 0.5394\n",
      "Epoch 92/100\n",
      "4468/4468 [==============================] - 0s 70us/step - loss: 0.7912 - accuracy: 0.5495\n",
      "Epoch 93/100\n",
      "4468/4468 [==============================] - 0s 69us/step - loss: 0.7738 - accuracy: 0.5419\n",
      "Epoch 94/100\n",
      "4468/4468 [==============================] - 0s 67us/step - loss: 0.7656 - accuracy: 0.5488\n",
      "Epoch 95/100\n",
      "4468/4468 [==============================] - 0s 68us/step - loss: 0.7704 - accuracy: 0.5454\n",
      "Epoch 96/100\n",
      "4468/4468 [==============================] - 0s 67us/step - loss: 0.8002 - accuracy: 0.5322\n",
      "Epoch 97/100\n",
      "4468/4468 [==============================] - 0s 67us/step - loss: 0.7720 - accuracy: 0.5448\n",
      "Epoch 98/100\n",
      "4468/4468 [==============================] - 0s 68us/step - loss: 0.7667 - accuracy: 0.5461\n",
      "Epoch 99/100\n",
      "4468/4468 [==============================] - 0s 66us/step - loss: 0.7670 - accuracy: 0.5436\n",
      "Epoch 100/100\n",
      "4468/4468 [==============================] - 0s 68us/step - loss: 0.7633 - accuracy: 0.5497\n"
     ]
    }
   ],
   "source": [
    "# Neural network\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(5, input_dim=41, activation='relu'))\n",
    "# model.add(Dense(10, activation='relu'))\n",
    "# model.add(Dense(10, activation='relu'))\n",
    "# model.add(Dense(10, activation='relu'))\n",
    "model.add(Dense(5, activation='relu'))\n",
    "model.add(Dense(5, activation='relu'))\n",
    "model.add(Dense(3, activation='relu'))\n",
    "model.compile(loss='categorical_hinge', optimizer='adam', metrics=['accuracy']) # categorical_crossentropy or categorical_hinge or squared_hinge \n",
    "history = model.fit(X_train, dummy_y_train, epochs=100)\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# categorigal hinge\n",
    "# with bias: shuffle False:20*2, relu hinge loss: 54.8\n",
    "# shuffle False:20*2, relu hinge loss: 55.3\n",
    "# 20*2: relu, sm,sm: 56.4\n",
    "# 20*2: sm,sm,sm\n",
    "# shuffle False:10*3, relu hinge loss: 54.8\n",
    "# shuffle False:10*5, relu hinge loss: 55.6\n",
    "# shuffle False:20*5, relu hinge loss: 57.7\n",
    "# shuffle False:40*5, relu hinge loss: 27\n",
    "# shuffle False:20*3, relu hinge loss: 27.2\n",
    "# shuffle False:20*8, relu hinge loss: 28\n",
    "\n",
    "# squared hinge: 30% inmost cases\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy is: 56.39686684073107\n"
     ]
    }
   ],
   "source": [
    "#Converting predictions to label\n",
    "pred = list()\n",
    "for i in range(len(y_pred)):\n",
    "    pred.append(np.argmax(y_pred[i]))\n",
    "\n",
    "#Converting one hot encoded test label to label\n",
    "test = list()\n",
    "for i in range(len(dummy_y_test)):\n",
    "    test.append(np.argmax(dummy_y_test[i]))\n",
    "    \n",
    "a = sklearn.metrics.accuracy_score(pred,test)\n",
    "print('Accuracy is:', a*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_estimators': 6}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rf = RandomForestClassifier(max_depth=1) # Stumps only, feature bagging with sqrt(# features), bootstrap samples\n",
    "rf_clf = GridSearchCV(rf, {'n_estimators':[3,6,9,12,15,18]})\n",
    "rf_clf.fit(X_train, y_train)\n",
    "\n",
    "# Best number of trees\n",
    "print(rf_clf.best_params_)\n",
    "\n",
    "# Test/train set AUC\n",
    "y_train_pred_rf = rf_clf.predict(X_train)\n",
    "y_test_pred_rf = rf_clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5161145926589078 0.5509138381201044\n"
     ]
    }
   ],
   "source": [
    "rf_train_score = sklearn.metrics.accuracy_score(y_train, y_train_pred_rf)\n",
    "rf_test_score = sklearn.metrics.accuracy_score(y_test, y_test_pred_rf)\n",
    "print(rf_train_score, rf_test_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Atr1 0.028\n",
      "Atr2 0.001\n",
      "Atr3 0.005\n",
      "Atr4 0.003\n",
      "Atr5 0.0\n",
      "Atr6 0.01\n",
      "Atr7 0.067\n",
      "Atr8 0.038\n",
      "Atr9 0.031\n",
      "Atr10 0.004\n",
      "Atr11 0.0\n",
      "Atr12 0.001\n",
      "Atr13 0.0\n",
      "Atr14 0.0\n",
      "Atr15 0.0\n",
      "Atr16 0.0\n",
      "Atr17 0.0\n",
      "Atr18 0.0\n",
      "Atr19 0.003\n",
      "Atr20 0.023\n",
      "Atr21 0.041\n",
      "Atr22 0.0\n",
      "Atr23 0.001\n",
      "Atr24 0.003\n",
      "Atr25 0.039\n",
      "Atr26 0.063\n",
      "Atr27 0.03\n",
      "Atr28 0.027\n",
      "Atr29 0.012\n",
      "Atr30 0.001\n",
      "Atr31 0.0\n",
      "Atr32 0.0\n",
      "Atr33 0.002\n",
      "Atr34 0.0\n",
      "Atr35 0.0\n",
      "Atr36 0.0\n",
      "Atr37 0.073\n",
      "Atr38 0.091\n",
      "Atr39 0.153\n",
      "Atr40 0.141\n",
      "Atr41 0.109\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([16, 15, 14, 13, 12, 10, 34, 31, 21, 35, 33,  4, 30, 17, 11, 29,  1,\n",
       "       22, 32, 23,  3, 18,  9,  2,  5, 28, 19, 27,  0, 26,  8,  7, 24, 20,\n",
       "       25,  6, 36, 37, 40, 39, 38])"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "rf = RandomForestClassifier(max_depth=1, n_estimators=1000) # Stumps only, feature bagging with sqrt(# features), bootstrap samples\n",
    "rf.fit(X,y)\n",
    "\n",
    "feat_imp = rf.feature_importances_\n",
    "for j in range(len(feat_imp)):\n",
    "    print('Atr{}'.format(j+1), feat_imp[j])\n",
    "\n",
    "# Print runtime\n",
    "feat_imp.argsort()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use top 10 features from random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "f=[7, 24, 20, 6, 25, 36, 37, 39, 40, 38]\n",
    "X_f=X[:,f]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best model is: {'estimator__n_neighbors': 200, 'estimator__p': 1, 'estimator__weights': 'distance'}\n",
      "\n",
      "The accuracy of the best model is: 0.5358072546925027\n",
      "Time to train 10.09\n",
      "Testing set accuracy 0.5634464751958225\n"
     ]
    }
   ],
   "source": [
    "#Define and fit model\n",
    "#Choose some parameters to search over\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_f, y, test_size=0.3, shuffle=False, random_state=0)\n",
    "params = {\n",
    "    'estimator__n_neighbors': [50,200,500],\n",
    "    \"estimator__weights\": ['distance'],\n",
    "    \"estimator__p\":[1]\n",
    "}\n",
    "model_to_set = OneVsRestClassifier(KNeighborsRegressor())\n",
    "model = GridSearchCV(model_to_set, params, cv=3, scoring='accuracy', return_train_score=True)\n",
    "t1=time.time()\n",
    "model.fit(X_train,y_train)\n",
    "\n",
    "#Print out some results\n",
    "print(\"The best model is:\",model.best_params_)\n",
    "print(\"\\nThe accuracy of the best model is:\", model.best_score_)\n",
    "t2=time.time()\n",
    "print(\"Time to train\", round(t2-t1,2))\n",
    "\n",
    "y_preds = model.predict(X_test)\n",
    "accuracy = sklearn.metrics.accuracy_score(y_test, y_preds)\n",
    "# fpr, tpr, thresholds = roc_curve(y_test, y_preds, pos_label=1)\n",
    "# auc_roc = auc(fpr, tpr)\n",
    "print(\"Testing set accuracy\",accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best model is: {'estimator__C': 10, 'estimator__kernel': 'linear'}\n",
      "\n",
      "The accuracy of the best model is: 0.5595347236933635\n",
      "Time to train 903.38\n",
      "Testing set accuracy 0.587467362924282\n"
     ]
    }
   ],
   "source": [
    "# with grid search \n",
    "X_train, X_test, y_train, y_test = train_test_split(X_f, y, test_size=0.3, shuffle=False, random_state=0)\n",
    "model_to_set = OneVsRestClassifier(SVC(gamma='scale'))\n",
    "parameters = {\n",
    "    \"estimator__C\": [0.1,1,10],\n",
    "    \"estimator__kernel\": [\"linear\",\"poly\",\"rbf\"],\n",
    "}\n",
    "t1=time.time()\n",
    "clfSV = GridSearchCV(model_to_set,cv=3,scoring='accuracy', param_grid=parameters)\n",
    "\n",
    "clfSV.fit(X_train,y_train)\n",
    "\n",
    "#Print out some results\n",
    "print(\"The best model is:\",clfSV.best_params_)\n",
    "print(\"\\nThe accuracy of the best model is:\", clfSV.best_score_)\n",
    "t2=time.time()\n",
    "print(\"Time to train\", round(t2-t1,2))\n",
    "\n",
    "\n",
    "y_preds = clfSV.predict(X_test)\n",
    "# fpr, tpr, thresholds = roc_curve(y_test, y_preds, pos_label=1)\n",
    "# auc_roc = auc(fpr, tpr)\n",
    "accuracy = sklearn.metrics.accuracy_score(y_test, y_preds)\n",
    "print(\"Testing set accuracy\",accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "4468/4468 [==============================] - 1s 324us/step - loss: 0.9935 - accuracy: 0.4830\n",
      "Epoch 2/100\n",
      "4468/4468 [==============================] - 0s 81us/step - loss: 0.9729 - accuracy: 0.4870\n",
      "Epoch 3/100\n",
      "4468/4468 [==============================] - 0s 78us/step - loss: 0.9367 - accuracy: 0.5128\n",
      "Epoch 4/100\n",
      "4468/4468 [==============================] - 0s 79us/step - loss: 0.9238 - accuracy: 0.5217\n",
      "Epoch 5/100\n",
      "4468/4468 [==============================] - 0s 76us/step - loss: 0.9172 - accuracy: 0.5215\n",
      "Epoch 6/100\n",
      "4468/4468 [==============================] - 0s 79us/step - loss: 0.9114 - accuracy: 0.5222\n",
      "Epoch 7/100\n",
      "4468/4468 [==============================] - 0s 79us/step - loss: 0.9088 - accuracy: 0.5237\n",
      "Epoch 8/100\n",
      "4468/4468 [==============================] - 0s 79us/step - loss: 0.9023 - accuracy: 0.5239\n",
      "Epoch 9/100\n",
      "4468/4468 [==============================] - 0s 82us/step - loss: 0.8963 - accuracy: 0.5233\n",
      "Epoch 10/100\n",
      "4468/4468 [==============================] - 0s 84us/step - loss: 0.8898 - accuracy: 0.5242\n",
      "Epoch 11/100\n",
      "4468/4468 [==============================] - 0s 91us/step - loss: 0.8819 - accuracy: 0.5266\n",
      "Epoch 12/100\n",
      "4468/4468 [==============================] - 0s 79us/step - loss: 0.8779 - accuracy: 0.5266\n",
      "Epoch 13/100\n",
      "4468/4468 [==============================] - 0s 86us/step - loss: 0.8739 - accuracy: 0.5295\n",
      "Epoch 14/100\n",
      "4468/4468 [==============================] - 0s 86us/step - loss: 0.8692 - accuracy: 0.5266\n",
      "Epoch 15/100\n",
      "4468/4468 [==============================] - 0s 90us/step - loss: 0.8678 - accuracy: 0.5311\n",
      "Epoch 16/100\n",
      "4468/4468 [==============================] - 0s 86us/step - loss: 0.8654 - accuracy: 0.5304\n",
      "Epoch 17/100\n",
      "4468/4468 [==============================] - 0s 78us/step - loss: 0.8621 - accuracy: 0.5316\n",
      "Epoch 18/100\n",
      "4468/4468 [==============================] - 0s 85us/step - loss: 0.8610 - accuracy: 0.5325\n",
      "Epoch 19/100\n",
      "4468/4468 [==============================] - 0s 85us/step - loss: 0.8601 - accuracy: 0.5340\n",
      "Epoch 20/100\n",
      "4468/4468 [==============================] - 0s 95us/step - loss: 0.8579 - accuracy: 0.5331\n",
      "Epoch 21/100\n",
      "4468/4468 [==============================] - 0s 86us/step - loss: 0.8554 - accuracy: 0.5367\n",
      "Epoch 22/100\n",
      "4468/4468 [==============================] - 0s 76us/step - loss: 0.8543 - accuracy: 0.5347\n",
      "Epoch 23/100\n",
      "4468/4468 [==============================] - 0s 75us/step - loss: 0.8523 - accuracy: 0.5380\n",
      "Epoch 24/100\n",
      "4468/4468 [==============================] - 0s 73us/step - loss: 0.8504 - accuracy: 0.5369\n",
      "Epoch 25/100\n",
      "4468/4468 [==============================] - 0s 74us/step - loss: 0.8508 - accuracy: 0.5394\n",
      "Epoch 26/100\n",
      "4468/4468 [==============================] - 0s 77us/step - loss: 0.8498 - accuracy: 0.5398\n",
      "Epoch 27/100\n",
      "4468/4468 [==============================] - 0s 88us/step - loss: 0.8470 - accuracy: 0.5405\n",
      "Epoch 28/100\n",
      "4468/4468 [==============================] - 0s 92us/step - loss: 0.8465 - accuracy: 0.5412\n",
      "Epoch 29/100\n",
      "4468/4468 [==============================] - 0s 93us/step - loss: 0.8456 - accuracy: 0.5383\n",
      "Epoch 30/100\n",
      "4468/4468 [==============================] - 0s 91us/step - loss: 0.8449 - accuracy: 0.5439\n",
      "Epoch 31/100\n",
      "4468/4468 [==============================] - 0s 82us/step - loss: 0.8417 - accuracy: 0.5412\n",
      "Epoch 32/100\n",
      "4468/4468 [==============================] - 0s 78us/step - loss: 0.8447 - accuracy: 0.5466\n",
      "Epoch 33/100\n",
      "4468/4468 [==============================] - 0s 80us/step - loss: 0.8416 - accuracy: 0.5445\n",
      "Epoch 34/100\n",
      "4468/4468 [==============================] - 0s 87us/step - loss: 0.8407 - accuracy: 0.5461\n",
      "Epoch 35/100\n",
      "4468/4468 [==============================] - 0s 96us/step - loss: 0.8388 - accuracy: 0.5515\n",
      "Epoch 36/100\n",
      "4468/4468 [==============================] - 0s 101us/step - loss: 0.8376 - accuracy: 0.5515\n",
      "Epoch 37/100\n",
      "4468/4468 [==============================] - 0s 85us/step - loss: 0.8374 - accuracy: 0.5535\n",
      "Epoch 38/100\n",
      "4468/4468 [==============================] - 0s 83us/step - loss: 0.8327 - accuracy: 0.5504\n",
      "Epoch 39/100\n",
      "4468/4468 [==============================] - 0s 81us/step - loss: 0.8341 - accuracy: 0.5524\n",
      "Epoch 40/100\n",
      "4468/4468 [==============================] - 0s 91us/step - loss: 0.8343 - accuracy: 0.5528\n",
      "Epoch 41/100\n",
      "4468/4468 [==============================] - 0s 82us/step - loss: 0.8317 - accuracy: 0.5553\n",
      "Epoch 42/100\n",
      "4468/4468 [==============================] - 0s 81us/step - loss: 0.8303 - accuracy: 0.5555\n",
      "Epoch 43/100\n",
      "4468/4468 [==============================] - 0s 77us/step - loss: 0.8312 - accuracy: 0.5557\n",
      "Epoch 44/100\n",
      "4468/4468 [==============================] - 0s 77us/step - loss: 0.8296 - accuracy: 0.5515\n",
      "Epoch 45/100\n",
      "4468/4468 [==============================] - 0s 75us/step - loss: 0.8275 - accuracy: 0.5575\n",
      "Epoch 46/100\n",
      "4468/4468 [==============================] - 0s 76us/step - loss: 0.8279 - accuracy: 0.5553\n",
      "Epoch 47/100\n",
      "4468/4468 [==============================] - 0s 77us/step - loss: 0.8262 - accuracy: 0.5537\n",
      "Epoch 48/100\n",
      "4468/4468 [==============================] - 0s 75us/step - loss: 0.8241 - accuracy: 0.5555\n",
      "Epoch 49/100\n",
      "4468/4468 [==============================] - 0s 75us/step - loss: 0.8265 - accuracy: 0.5510\n",
      "Epoch 50/100\n",
      "4468/4468 [==============================] - 0s 78us/step - loss: 0.8228 - accuracy: 0.5513\n",
      "Epoch 51/100\n",
      "4468/4468 [==============================] - 0s 76us/step - loss: 0.8218 - accuracy: 0.5582\n",
      "Epoch 52/100\n",
      "4468/4468 [==============================] - 0s 83us/step - loss: 0.8181 - accuracy: 0.5564\n",
      "Epoch 53/100\n",
      "4468/4468 [==============================] - 0s 87us/step - loss: 0.8179 - accuracy: 0.5542\n",
      "Epoch 54/100\n",
      "4468/4468 [==============================] - 0s 84us/step - loss: 0.8197 - accuracy: 0.5553\n",
      "Epoch 55/100\n",
      "4468/4468 [==============================] - 0s 89us/step - loss: 0.8171 - accuracy: 0.5580\n",
      "Epoch 56/100\n",
      "4468/4468 [==============================] - 0s 88us/step - loss: 0.8176 - accuracy: 0.5611\n",
      "Epoch 57/100\n",
      "4468/4468 [==============================] - 0s 82us/step - loss: 0.8185 - accuracy: 0.5566\n",
      "Epoch 58/100\n",
      "4468/4468 [==============================] - 0s 92us/step - loss: 0.8159 - accuracy: 0.5548\n",
      "Epoch 59/100\n",
      "4468/4468 [==============================] - 0s 78us/step - loss: 0.8120 - accuracy: 0.5582\n",
      "Epoch 60/100\n",
      "4468/4468 [==============================] - 0s 78us/step - loss: 0.8153 - accuracy: 0.5557\n",
      "Epoch 61/100\n",
      "4468/4468 [==============================] - 0s 78us/step - loss: 0.8154 - accuracy: 0.5533\n",
      "Epoch 62/100\n",
      "4468/4468 [==============================] - 0s 81us/step - loss: 0.8126 - accuracy: 0.5513\n",
      "Epoch 63/100\n",
      "4468/4468 [==============================] - 0s 79us/step - loss: 0.8139 - accuracy: 0.5624\n",
      "Epoch 64/100\n",
      "4468/4468 [==============================] - 0s 81us/step - loss: 0.8105 - accuracy: 0.5524\n",
      "Epoch 65/100\n",
      "4468/4468 [==============================] - 0s 81us/step - loss: 0.8100 - accuracy: 0.5544\n",
      "Epoch 66/100\n",
      "4468/4468 [==============================] - 0s 84us/step - loss: 0.8115 - accuracy: 0.5551\n",
      "Epoch 67/100\n",
      "4468/4468 [==============================] - 0s 86us/step - loss: 0.8102 - accuracy: 0.5582\n",
      "Epoch 68/100\n",
      "4468/4468 [==============================] - 0s 85us/step - loss: 0.8109 - accuracy: 0.5586\n",
      "Epoch 69/100\n",
      "4468/4468 [==============================] - 0s 84us/step - loss: 0.8070 - accuracy: 0.5551\n",
      "Epoch 70/100\n",
      "4468/4468 [==============================] - 0s 84us/step - loss: 0.8126 - accuracy: 0.5553\n",
      "Epoch 71/100\n",
      "4468/4468 [==============================] - 0s 82us/step - loss: 0.8073 - accuracy: 0.5546\n",
      "Epoch 72/100\n",
      "4468/4468 [==============================] - 0s 84us/step - loss: 0.8064 - accuracy: 0.5564\n",
      "Epoch 73/100\n",
      "4468/4468 [==============================] - 0s 87us/step - loss: 0.8072 - accuracy: 0.5575\n",
      "Epoch 74/100\n",
      "4468/4468 [==============================] - 0s 81us/step - loss: 0.8100 - accuracy: 0.5546\n",
      "Epoch 75/100\n",
      "4468/4468 [==============================] - 0s 81us/step - loss: 0.8069 - accuracy: 0.5582\n",
      "Epoch 76/100\n",
      "4468/4468 [==============================] - 0s 78us/step - loss: 0.8065 - accuracy: 0.5600\n",
      "Epoch 77/100\n",
      "4468/4468 [==============================] - 0s 90us/step - loss: 0.8038 - accuracy: 0.5582\n",
      "Epoch 78/100\n",
      "4468/4468 [==============================] - 0s 87us/step - loss: 0.8096 - accuracy: 0.5553\n",
      "Epoch 79/100\n",
      "4468/4468 [==============================] - 0s 85us/step - loss: 0.8061 - accuracy: 0.5542\n",
      "Epoch 80/100\n",
      "4468/4468 [==============================] - 0s 87us/step - loss: 0.8075 - accuracy: 0.5589\n",
      "Epoch 81/100\n",
      "4468/4468 [==============================] - 0s 102us/step - loss: 0.8053 - accuracy: 0.5598\n",
      "Epoch 82/100\n",
      "4468/4468 [==============================] - 0s 90us/step - loss: 0.8065 - accuracy: 0.5580\n",
      "Epoch 83/100\n",
      "4468/4468 [==============================] - 0s 87us/step - loss: 0.8051 - accuracy: 0.5544\n",
      "Epoch 84/100\n",
      "4468/4468 [==============================] - 0s 86us/step - loss: 0.8016 - accuracy: 0.5546\n",
      "Epoch 85/100\n",
      "4468/4468 [==============================] - 0s 82us/step - loss: 0.8020 - accuracy: 0.5526\n",
      "Epoch 86/100\n",
      "4468/4468 [==============================] - 0s 80us/step - loss: 0.8035 - accuracy: 0.5609\n",
      "Epoch 87/100\n",
      "4468/4468 [==============================] - 0s 86us/step - loss: 0.8009 - accuracy: 0.5573\n",
      "Epoch 88/100\n",
      "4468/4468 [==============================] - 0s 80us/step - loss: 0.8071 - accuracy: 0.5577\n",
      "Epoch 89/100\n",
      "4468/4468 [==============================] - 0s 79us/step - loss: 0.8044 - accuracy: 0.5580\n",
      "Epoch 90/100\n",
      "4468/4468 [==============================] - 0s 80us/step - loss: 0.8021 - accuracy: 0.5584\n",
      "Epoch 91/100\n",
      "4468/4468 [==============================] - 0s 84us/step - loss: 0.8049 - accuracy: 0.5586\n",
      "Epoch 92/100\n",
      "4468/4468 [==============================] - 0s 80us/step - loss: 0.7993 - accuracy: 0.5638\n",
      "Epoch 93/100\n",
      "4468/4468 [==============================] - 0s 80us/step - loss: 0.8050 - accuracy: 0.5568\n",
      "Epoch 94/100\n",
      "4468/4468 [==============================] - 0s 78us/step - loss: 0.8027 - accuracy: 0.5486\n",
      "Epoch 95/100\n",
      "4468/4468 [==============================] - 0s 84us/step - loss: 0.8028 - accuracy: 0.5510\n",
      "Epoch 96/100\n",
      "4468/4468 [==============================] - 0s 81us/step - loss: 0.8042 - accuracy: 0.5483\n",
      "Epoch 97/100\n",
      "4468/4468 [==============================] - 0s 89us/step - loss: 0.8070 - accuracy: 0.5589\n",
      "Epoch 98/100\n",
      "4468/4468 [==============================] - 0s 91us/step - loss: 0.8051 - accuracy: 0.5562\n",
      "Epoch 99/100\n",
      "4468/4468 [==============================] - 0s 86us/step - loss: 0.8008 - accuracy: 0.5593\n",
      "Epoch 100/100\n",
      "4468/4468 [==============================] - 0s 88us/step - loss: 0.8001 - accuracy: 0.5548\n"
     ]
    }
   ],
   "source": [
    "\n",
    "X_f=X[:,f]\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from keras.utils import np_utils\n",
    "\n",
    "o=np.ones(X.shape[0])\n",
    "o=o.reshape(X.shape[0],1)\n",
    "\n",
    "# X=np.hstack((X,o))\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_f, y, test_size=0.3, shuffle=False, random_state=0)\n",
    "\n",
    "encoder = LabelEncoder()\n",
    "\n",
    "# training\n",
    "encoder.fit(y_train)\n",
    "encoded_y_train = encoder.transform(y_train)\n",
    "# convert integers to dummy variables (i.e. one hot encoded)\n",
    "dummy_y_train = np_utils.to_categorical(encoded_y_train)\n",
    "# testing\n",
    "encoder.fit(y_test)\n",
    "encoded_y_test = encoder.transform(y_test)\n",
    "# convert integers to dummy variables (i.e. one hot encoded)\n",
    "dummy_y_test = np_utils.to_categorical(encoded_y_test)\n",
    "\n",
    "# Neural network\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(5, input_dim=10, activation='relu'))\n",
    "num_layers=5\n",
    "for i in range(max(0,num_layers-1)):\n",
    "    model.add(Dense(5, activation='relu'))\n",
    "model.add(Dense(3, activation='relu'))\n",
    "model.compile(loss='categorical_hinge', optimizer='adam', metrics=['accuracy']) # categorical_crossentropy or categorical_hinge or squared_hinge \n",
    "history = model.fit(X_train, dummy_y_train, epochs=100)\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "## 2*5: 57.6\n",
    "## 5*5: 58.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy is: 58.38120104438642\n"
     ]
    }
   ],
   "source": [
    "#Converting predictions to label\n",
    "pred = list()\n",
    "for i in range(len(y_pred)):\n",
    "    pred.append(np.argmax(y_pred[i]))\n",
    "\n",
    "#Converting one hot encoded test label to label\n",
    "test = list()\n",
    "for i in range(len(dummy_y_test)):\n",
    "    test.append(np.argmax(dummy_y_test[i]))\n",
    "    \n",
    "a = sklearn.metrics.accuracy_score(pred,test)\n",
    "print('Accuracy is:', a*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy is: 58.38120104438642\n"
     ]
    }
   ],
   "source": [
    "from keras.utils.vis_utils import plot_model\n",
    "model = Sequential()\n",
    "model.add(Dense(2, input_dim=1, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "plot_model(model, to_file='model_plot.png', show_shapes=True, show_layer_names=True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components = 20)\n",
    "X_train_pca = pca.fit_transform(X_train)\n",
    "X_test_pca = pca.fit_transform(X_test)\n",
    "# comment below if without PCA\n",
    "X_train=X_train_pca\n",
    "X_test=X_test_pca"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best model is: {'estimator__C': 1, 'estimator__kernel': 'linear'}\n",
      "\n",
      "The accuracy of the best model is: 0.4986554644574756\n",
      "Time to train 5.18\n",
      "Testing set accuracy 0.5075718015665797\n"
     ]
    }
   ],
   "source": [
    "# with grid search \n",
    "model_to_set = OneVsRestClassifier(SVC(gamma='scale'))\n",
    "parameters = {\n",
    "    \"estimator__C\": [0.1,1,10],\n",
    "    \"estimator__kernel\": [\"linear\"],\n",
    "}\n",
    "t1=time.time()\n",
    "clfSV = GridSearchCV(model_to_set,cv=3,scoring='accuracy', param_grid=parameters)\n",
    "\n",
    "clfSV.fit(X_train,y_train)\n",
    "\n",
    "#Print out some results\n",
    "print(\"The best model is:\",clfSV.best_params_)\n",
    "print(\"\\nThe accuracy of the best model is:\", clfSV.best_score_)\n",
    "t2=time.time()\n",
    "print(\"Time to train\", round(t2-t1,2))\n",
    "\n",
    "\n",
    "y_preds = clfSV.predict(X_test)\n",
    "# fpr, tpr, thresholds = roc_curve(y_test, y_preds, pos_label=1)\n",
    "# auc_roc = auc(fpr, tpr)\n",
    "accuracy = sklearn.metrics.accuracy_score(y_test, y_preds)\n",
    "print(\"Testing set accuracy\",accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### NN\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "4468/4468 [==============================] - 1s 168us/step - loss: 1.0007 - accuracy: 0.2811\n",
      "Epoch 2/100\n",
      "4468/4468 [==============================] - 0s 42us/step - loss: 1.0000 - accuracy: 0.2849\n",
      "Epoch 3/100\n",
      "4468/4468 [==============================] - 0s 44us/step - loss: 1.0000 - accuracy: 0.2847\n",
      "Epoch 4/100\n",
      "4468/4468 [==============================] - 0s 44us/step - loss: 1.0000 - accuracy: 0.2851\n",
      "Epoch 5/100\n",
      "4468/4468 [==============================] - 0s 43us/step - loss: 1.0000 - accuracy: 0.2851\n",
      "Epoch 6/100\n",
      "4468/4468 [==============================] - 0s 43us/step - loss: 1.0000 - accuracy: 0.2851\n",
      "Epoch 7/100\n",
      "4468/4468 [==============================] - 0s 46us/step - loss: 1.0000 - accuracy: 0.2854\n",
      "Epoch 8/100\n",
      "4468/4468 [==============================] - 0s 43us/step - loss: 1.0000 - accuracy: 0.2856\n",
      "Epoch 9/100\n",
      "4468/4468 [==============================] - 0s 40us/step - loss: 1.0000 - accuracy: 0.2863\n",
      "Epoch 10/100\n",
      "4468/4468 [==============================] - 0s 43us/step - loss: 1.0000 - accuracy: 0.2851\n",
      "Epoch 11/100\n",
      "4468/4468 [==============================] - 0s 43us/step - loss: 1.0000 - accuracy: 0.2849\n",
      "Epoch 12/100\n",
      "4468/4468 [==============================] - 0s 45us/step - loss: 1.0000 - accuracy: 0.2860\n",
      "Epoch 13/100\n",
      "4468/4468 [==============================] - 0s 40us/step - loss: 0.9999 - accuracy: 0.2867\n",
      "Epoch 14/100\n",
      "4468/4468 [==============================] - 0s 42us/step - loss: 0.9999 - accuracy: 0.2860\n",
      "Epoch 15/100\n",
      "4468/4468 [==============================] - 0s 40us/step - loss: 0.9999 - accuracy: 0.2858\n",
      "Epoch 16/100\n",
      "4468/4468 [==============================] - 0s 40us/step - loss: 0.9999 - accuracy: 0.2869\n",
      "Epoch 17/100\n",
      "4468/4468 [==============================] - 0s 41us/step - loss: 0.9999 - accuracy: 0.2863\n",
      "Epoch 18/100\n",
      "4468/4468 [==============================] - 0s 41us/step - loss: 0.9999 - accuracy: 0.2860\n",
      "Epoch 19/100\n",
      "4468/4468 [==============================] - 0s 40us/step - loss: 0.9998 - accuracy: 0.2863\n",
      "Epoch 20/100\n",
      "4468/4468 [==============================] - 0s 43us/step - loss: 0.9998 - accuracy: 0.2863\n",
      "Epoch 21/100\n",
      "4468/4468 [==============================] - 0s 43us/step - loss: 0.9998 - accuracy: 0.2865\n",
      "Epoch 22/100\n",
      "4468/4468 [==============================] - 0s 47us/step - loss: 0.9998 - accuracy: 0.2880\n",
      "Epoch 23/100\n",
      "4468/4468 [==============================] - 0s 44us/step - loss: 0.9998 - accuracy: 0.2876\n",
      "Epoch 24/100\n",
      "4468/4468 [==============================] - 0s 40us/step - loss: 0.9997 - accuracy: 0.2885\n",
      "Epoch 25/100\n",
      "4468/4468 [==============================] - 0s 40us/step - loss: 0.9997 - accuracy: 0.2930\n",
      "Epoch 26/100\n",
      "4468/4468 [==============================] - 0s 41us/step - loss: 0.9955 - accuracy: 0.3462\n",
      "Epoch 27/100\n",
      "4468/4468 [==============================] - 0s 44us/step - loss: 0.9391 - accuracy: 0.4832\n",
      "Epoch 28/100\n",
      "4468/4468 [==============================] - 0s 49us/step - loss: 0.9207 - accuracy: 0.4937\n",
      "Epoch 29/100\n",
      "4468/4468 [==============================] - 0s 42us/step - loss: 0.9160 - accuracy: 0.4924\n",
      "Epoch 30/100\n",
      "4468/4468 [==============================] - 0s 48us/step - loss: 0.9127 - accuracy: 0.4924\n",
      "Epoch 31/100\n",
      "4468/4468 [==============================] - 0s 42us/step - loss: 0.9106 - accuracy: 0.4915\n",
      "Epoch 32/100\n",
      "4468/4468 [==============================] - 0s 40us/step - loss: 0.9086 - accuracy: 0.4922\n",
      "Epoch 33/100\n",
      "4468/4468 [==============================] - 0s 43us/step - loss: 0.9074 - accuracy: 0.4913\n",
      "Epoch 34/100\n",
      "4468/4468 [==============================] - 0s 45us/step - loss: 0.9064 - accuracy: 0.4919\n",
      "Epoch 35/100\n",
      "4468/4468 [==============================] - 0s 41us/step - loss: 0.9054 - accuracy: 0.4919\n",
      "Epoch 36/100\n",
      "4468/4468 [==============================] - 0s 49us/step - loss: 0.9045 - accuracy: 0.4933\n",
      "Epoch 37/100\n",
      "4468/4468 [==============================] - 0s 54us/step - loss: 0.9031 - accuracy: 0.4917\n",
      "Epoch 38/100\n",
      "4468/4468 [==============================] - 0s 50us/step - loss: 0.9020 - accuracy: 0.4908\n",
      "Epoch 39/100\n",
      "4468/4468 [==============================] - 0s 42us/step - loss: 0.9010 - accuracy: 0.4917\n",
      "Epoch 40/100\n",
      "4468/4468 [==============================] - 0s 40us/step - loss: 0.8996 - accuracy: 0.4908\n",
      "Epoch 41/100\n",
      "4468/4468 [==============================] - 0s 43us/step - loss: 0.8980 - accuracy: 0.4913\n",
      "Epoch 42/100\n",
      "4468/4468 [==============================] - 0s 44us/step - loss: 0.8965 - accuracy: 0.4893\n",
      "Epoch 43/100\n",
      "4468/4468 [==============================] - 0s 43us/step - loss: 0.8951 - accuracy: 0.4908\n",
      "Epoch 44/100\n",
      "4468/4468 [==============================] - 0s 41us/step - loss: 0.8933 - accuracy: 0.4928\n",
      "Epoch 45/100\n",
      "4468/4468 [==============================] - 0s 42us/step - loss: 0.8915 - accuracy: 0.4910\n",
      "Epoch 46/100\n",
      "4468/4468 [==============================] - 0s 42us/step - loss: 0.8898 - accuracy: 0.4924\n",
      "Epoch 47/100\n",
      "4468/4468 [==============================] - 0s 41us/step - loss: 0.8888 - accuracy: 0.4924\n",
      "Epoch 48/100\n",
      "4468/4468 [==============================] - 0s 41us/step - loss: 0.8872 - accuracy: 0.4917\n",
      "Epoch 49/100\n",
      "4468/4468 [==============================] - 0s 41us/step - loss: 0.8871 - accuracy: 0.4904\n",
      "Epoch 50/100\n",
      "4468/4468 [==============================] - 0s 41us/step - loss: 0.8860 - accuracy: 0.4919\n",
      "Epoch 51/100\n",
      "4468/4468 [==============================] - 0s 42us/step - loss: 0.8856 - accuracy: 0.4919\n",
      "Epoch 52/100\n",
      "4468/4468 [==============================] - 0s 42us/step - loss: 0.8852 - accuracy: 0.4910\n",
      "Epoch 53/100\n",
      "4468/4468 [==============================] - 0s 44us/step - loss: 0.8843 - accuracy: 0.4935\n",
      "Epoch 54/100\n",
      "4468/4468 [==============================] - 0s 44us/step - loss: 0.8838 - accuracy: 0.4922\n",
      "Epoch 55/100\n",
      "4468/4468 [==============================] - 0s 43us/step - loss: 0.8838 - accuracy: 0.4913\n",
      "Epoch 56/100\n",
      "4468/4468 [==============================] - 0s 44us/step - loss: 0.8832 - accuracy: 0.4915\n",
      "Epoch 57/100\n",
      "4468/4468 [==============================] - 0s 48us/step - loss: 0.8828 - accuracy: 0.4910\n",
      "Epoch 58/100\n",
      "4468/4468 [==============================] - 0s 49us/step - loss: 0.8827 - accuracy: 0.4926\n",
      "Epoch 59/100\n",
      "4468/4468 [==============================] - 0s 48us/step - loss: 0.8819 - accuracy: 0.4906\n",
      "Epoch 60/100\n",
      "4468/4468 [==============================] - 0s 46us/step - loss: 0.8817 - accuracy: 0.4917\n",
      "Epoch 61/100\n",
      "4468/4468 [==============================] - 0s 48us/step - loss: 0.8814 - accuracy: 0.4906\n",
      "Epoch 62/100\n",
      "4468/4468 [==============================] - 0s 47us/step - loss: 0.8809 - accuracy: 0.4908\n",
      "Epoch 63/100\n",
      "4468/4468 [==============================] - 0s 52us/step - loss: 0.8808 - accuracy: 0.4908\n",
      "Epoch 64/100\n",
      "4468/4468 [==============================] - 0s 48us/step - loss: 0.8798 - accuracy: 0.4895\n",
      "Epoch 65/100\n",
      "4468/4468 [==============================] - 0s 55us/step - loss: 0.8793 - accuracy: 0.4897\n",
      "Epoch 66/100\n",
      "4468/4468 [==============================] - 0s 48us/step - loss: 0.8798 - accuracy: 0.4899\n",
      "Epoch 67/100\n",
      "4468/4468 [==============================] - 0s 47us/step - loss: 0.8791 - accuracy: 0.4908\n",
      "Epoch 68/100\n",
      "4468/4468 [==============================] - 0s 55us/step - loss: 0.8782 - accuracy: 0.4906\n",
      "Epoch 69/100\n",
      "4468/4468 [==============================] - 0s 57us/step - loss: 0.8782 - accuracy: 0.4908\n",
      "Epoch 70/100\n",
      "4468/4468 [==============================] - 0s 46us/step - loss: 0.8774 - accuracy: 0.4895\n",
      "Epoch 71/100\n",
      "4468/4468 [==============================] - 0s 44us/step - loss: 0.8769 - accuracy: 0.4904\n",
      "Epoch 72/100\n",
      "4468/4468 [==============================] - 0s 46us/step - loss: 0.8768 - accuracy: 0.4906\n",
      "Epoch 73/100\n",
      "4468/4468 [==============================] - 0s 46us/step - loss: 0.8762 - accuracy: 0.4910\n",
      "Epoch 74/100\n",
      "4468/4468 [==============================] - 0s 50us/step - loss: 0.8759 - accuracy: 0.4915\n",
      "Epoch 75/100\n",
      "4468/4468 [==============================] - 0s 46us/step - loss: 0.8758 - accuracy: 0.4908\n",
      "Epoch 76/100\n",
      "4468/4468 [==============================] - 0s 43us/step - loss: 0.8750 - accuracy: 0.4913\n",
      "Epoch 77/100\n",
      "4468/4468 [==============================] - 0s 45us/step - loss: 0.8752 - accuracy: 0.4908\n",
      "Epoch 78/100\n",
      "4468/4468 [==============================] - 0s 53us/step - loss: 0.8749 - accuracy: 0.4913\n",
      "Epoch 79/100\n",
      "4468/4468 [==============================] - 0s 52us/step - loss: 0.8749 - accuracy: 0.4917\n",
      "Epoch 80/100\n",
      "4468/4468 [==============================] - 0s 49us/step - loss: 0.8744 - accuracy: 0.4910\n",
      "Epoch 81/100\n",
      "4468/4468 [==============================] - 0s 48us/step - loss: 0.8745 - accuracy: 0.4922\n",
      "Epoch 82/100\n",
      "4468/4468 [==============================] - 0s 50us/step - loss: 0.8735 - accuracy: 0.4931\n",
      "Epoch 83/100\n",
      "4468/4468 [==============================] - 0s 52us/step - loss: 0.8740 - accuracy: 0.4913\n",
      "Epoch 84/100\n",
      "4468/4468 [==============================] - 0s 59us/step - loss: 0.8736 - accuracy: 0.4922\n",
      "Epoch 85/100\n",
      "4468/4468 [==============================] - 0s 76us/step - loss: 0.8731 - accuracy: 0.4933\n",
      "Epoch 86/100\n",
      "4468/4468 [==============================] - 0s 68us/step - loss: 0.8729 - accuracy: 0.4935\n",
      "Epoch 87/100\n",
      "4468/4468 [==============================] - 0s 79us/step - loss: 0.8732 - accuracy: 0.4931\n",
      "Epoch 88/100\n",
      "4468/4468 [==============================] - 0s 62us/step - loss: 0.8735 - accuracy: 0.4924\n",
      "Epoch 89/100\n",
      "4468/4468 [==============================] - 0s 59us/step - loss: 0.8722 - accuracy: 0.4928\n",
      "Epoch 90/100\n",
      "4468/4468 [==============================] - 0s 61us/step - loss: 0.8719 - accuracy: 0.4931\n",
      "Epoch 91/100\n",
      "4468/4468 [==============================] - 0s 48us/step - loss: 0.8719 - accuracy: 0.4933\n",
      "Epoch 92/100\n",
      "4468/4468 [==============================] - 0s 48us/step - loss: 0.8713 - accuracy: 0.4940\n",
      "Epoch 93/100\n",
      "4468/4468 [==============================] - 0s 46us/step - loss: 0.8712 - accuracy: 0.4942\n",
      "Epoch 94/100\n",
      "4468/4468 [==============================] - 0s 46us/step - loss: 0.8710 - accuracy: 0.4937\n",
      "Epoch 95/100\n",
      "4468/4468 [==============================] - 0s 46us/step - loss: 0.8715 - accuracy: 0.4944\n",
      "Epoch 96/100\n",
      "4468/4468 [==============================] - 0s 45us/step - loss: 0.8704 - accuracy: 0.4946\n",
      "Epoch 97/100\n",
      "4468/4468 [==============================] - 0s 46us/step - loss: 0.8703 - accuracy: 0.4944\n",
      "Epoch 98/100\n",
      "4468/4468 [==============================] - 0s 44us/step - loss: 0.8701 - accuracy: 0.4955\n",
      "Epoch 99/100\n",
      "4468/4468 [==============================] - 0s 44us/step - loss: 0.8703 - accuracy: 0.4942\n",
      "Epoch 100/100\n",
      "4468/4468 [==============================] - 0s 44us/step - loss: 0.8701 - accuracy: 0.4946\n",
      "Accuracy is: 44.02088772845953\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from keras.utils import np_utils\n",
    "\n",
    "o=np.ones(X.shape[0])\n",
    "o=o.reshape(X.shape[0],1)\n",
    "\n",
    "# X=np.hstack((X,o))\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X_f, y, test_size=0.3, shuffle=False)\n",
    "\n",
    "encoder = LabelEncoder()\n",
    "\n",
    "# training\n",
    "encoder.fit(y_train)\n",
    "encoded_y_train = encoder.transform(y_train)\n",
    "# convert integers to dummy variables (i.e. one hot encoded)\n",
    "dummy_y_train = np_utils.to_categorical(encoded_y_train)\n",
    "# testing\n",
    "encoder.fit(y_test)\n",
    "encoded_y_test = encoder.transform(y_test)\n",
    "# convert integers to dummy variables (i.e. one hot encoded)\n",
    "dummy_y_test = np_utils.to_categorical(encoded_y_test)\n",
    "\n",
    "# Neural network\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(5, input_dim=20, activation='relu'))\n",
    "model.add(Dense(5, activation='relu'))\n",
    "model.add(Dense(5, activation='relu'))\n",
    "model.add(Dense(3, activation='relu'))\n",
    "model.compile(loss='categorical_hinge', optimizer='adam', metrics=['accuracy']) # categorical_crossentropy or categorical_hinge or squared_hinge \n",
    "history = model.fit(X_train, dummy_y_train, epochs=100)\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "#Converting predictions to label\n",
    "pred = list()\n",
    "for i in range(len(y_pred)):\n",
    "    pred.append(np.argmax(y_pred[i]))\n",
    "\n",
    "#Converting one hot encoded test label to label\n",
    "test = list()\n",
    "for i in range(len(dummy_y_test)):\n",
    "    test.append(np.argmax(dummy_y_test[i]))\n",
    "    \n",
    "a = sklearn.metrics.accuracy_score(pred,test)\n",
    "print('Accuracy is:', a*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best model is: {'estimator__n_neighbors': 200, 'estimator__p': 2, 'estimator__weights': 'distance'}\n",
      "\n",
      "The accuracy of the best model is: 0.5055944938497527\n",
      "Time to train 31.75\n",
      "Testing set accuracy 0.5143603133159269\n"
     ]
    }
   ],
   "source": [
    "#Define and fit model\n",
    "#Choose some parameters to search over\n",
    "params = {\n",
    "    'estimator__n_neighbors': [20,50,200,500],\n",
    "    \"estimator__weights\": ['distance'],\n",
    "    \"estimator__p\":[1,2]\n",
    "}\n",
    "model_to_set = OneVsRestClassifier(KNeighborsRegressor())\n",
    "model = GridSearchCV(model_to_set, params, cv=3, scoring='accuracy', return_train_score=True)\n",
    "t1=time.time()\n",
    "model.fit(X_train,y_train)\n",
    "\n",
    "#Print out some results\n",
    "print(\"The best model is:\",model.best_params_)\n",
    "print(\"\\nThe accuracy of the best model is:\", model.best_score_)\n",
    "t2=time.time()\n",
    "print(\"Time to train\", round(t2-t1,2))\n",
    "\n",
    "y_preds = model.predict(X_test)\n",
    "accuracy = sklearn.metrics.accuracy_score(y_test, y_preds)\n",
    "# fpr, tpr, thresholds = roc_curve(y_test, y_preds, pos_label=1)\n",
    "# auc_roc = auc(fpr, tpr)\n",
    "print(\"Testing set accuracy\",accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['AS-H', 'HS-A', 'FTR-A', 'HS-H', 'AS-A', 'HomeForm', 'AwayForm',\n",
       "       'HomePreviousPosition', 'AwayPreviousPosition', 'PreviousEncounters'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print top 10 features in RF\n",
    "f=[7, 24, 20, 6, 25, 36, 37, 39, 40, 38]\n",
    "pd_features = finalData.drop(columns=['FTR'])\n",
    "pd_features.columns[f]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
